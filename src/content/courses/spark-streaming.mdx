---
benefits:
  hours: 11
  linesOfCode: 2200
category: spark
description: Learn Spark Streaming on big data in real time with Scala. Integrate any data source, from Kafka to Twitter.
excerpt: <p>Process massive data as <strong>it arrives</strong>. Integrate Spark with Kafka, JDBC, Cassandra and anything you want. Process live tweets in real time and stream data like you own it.</p>
faqs:
  - question: How long is the course? Will I have time for it?
    answer: The course is a full 11 hours in length, with lessons 20-30 minutes each, and we write 2200 lines of code. For a complex topic like Spark Streaming, I don't believe in 5-minute lectures or in fill-in-the-blanks quizzes. To learn Spark Streaming in the most effective way, I recommend chunks of 1 hour of learning at a time.
  - question: How will I learn Spark Streaming in this course?
    answer: Code is king, and we write from scratch. In a typical lesson I'll explain some concepts in short, then I'll dive right into the code. We'll write it together, and at every topic I will give you exercises. You'll usually pause the video to try them yourself, after which I will also solve them on camera.
  - question: Can I expense this at my company?
    answer: Of course! Most (wise) companies will reimburse employees taking courses like this, and it's a really cheap training for them.
  - question: Is Spark Streaming difficult to learn?
    answer: It could be, if you're learning on your own, but I've designed this course with a clear learning path that you can follow step by step. The course was designed to give you a challenge so you're not bored, but not so much that you flip the table in anger. In case you struggle, we have a community willing to help, and I'm responsive for questions!
  - question: What if I'm not happy with the course?
    answer: If you're not 100% happy with the course, I want you to have your money back. It's a risk-free investment.
  - question: Daniel, I can't afford the course. What do I do?
    answer: For a while, I told everyone who could not afford the course to email me and I gave them discounts. But then I looked at the stats. Almost all the people who actually took the time and completed the course had paid for it in full. So I'm not offering discounts anymore. This is an investment in yourself, which will pay off 100x if you commit.
  - question: I have very little Scala or Spark experience. Can I learn Spark Streaming?
    answer: I don't recommend diving into Spark Streaming without any previous Spark experience. We have two recap lessons at the beginning, but they're not a crash course into Scala or Spark. You should take the Scala beginners course and the Spark Essentials course at least.
  - question: What is Spark Streaming anyway?
    answer: Spark Streaming is an extension to the the popular big data computing engine Apache Spark. While the "classical" Spark engine allows you to process massive data of any scale in a "static" way (data at rest), Spark Streaming gives you the opportunity to process data at scale immediately as it arrives, hence allowing you to process potentially infinite amounts of data.
image: ./spark-streaming.jpeg
price: 75
purchaseLink: https://sso.teachable.com/secure/256201/checkout/3886435/spark-streaming
title: Spark Streaming
pricingPlanId: 3886435
---

import CourseLayout from "@pages/courses/_layouts/CourseLayout.astro";

<CourseLayout>
  <Fragment slot="goal">
    ### Nothing static, all in motion.

    You probably know by now: Spark is the most popular computing engine for big data, the most maintained, and with a proven track record of performance. It's 100 times faster than the old MapReduce paradigm, and can easily be extended with machine learning and streaming capabilities, and much more.

    In this Spark Streaming course, we'll take the natural step forward: process big data as it arrives.

    ### What's in for you:

      - <p>You'll learn how Spark Structured Streaming and "normal" Spark batch operations are similar and different</p>
      - <p>You'll work with new streaming abstractions (DStreams) for low-level, high-control processing</p>
      - <p>You'll integrate Kafka, JDBC, Cassandra and Akka Streams (!) so that you can later integrate anything you like</p>
      - <p>You'll work with powerful stateful APIs that only a few know how to properly use</p>
    And some extra perks:
      - <p>You'll have access to the entire code I write on camera (2200+ LOC)</p>
      - <p>You'll be invited to our private Slack room where I'll share latest updates, discounts, talks, conferences, and recruitment opportunities</p>
      - <p>(soon) You'll have access to the takeaway slides</p>
      - <p>(soon) You'll be able to download the videos for your offline view</p>

  </Fragment>
  <Fragment slot="skills">
    ### Skills you'll get:

    - <p>Same comfort with Spark Structured Streaming APIs as with "normal" Spark batch:</p>
      - <p>projections</p>
      - <p>joins</p>
      - <p>aggregations</p>
      - <p>sums</p>
      - <p>groups</p>
    - <p>High control over how data is processed with DStreams:</p>
      - <p>map, flatMap, filter</p>
      - <p>transform</p>
      - <p>by-key operations</p>
      - <p>process each RDD individually</p>
    - <p>Ability to work with time columns and window functions, both on structured and low-level streams</p>
      - <p>sliding windows</p>
      - <p>tumbling windows</p>
      - <p>reduce by window</p>
      - <p>reduce by window and key</p>
    - <p>Integration between Spark and other data sources, including</p>
      - <p>Kafka (structured and low-level)</p>
      - <p>JDBC</p>
      - <p>NoSQL</p>
      - <p>and something that's not "natural" to Spark, like Akka</p>
    - <p>Ability to manually manage stateful data processing in ways SQL is incapable of</p>
      - <p>mapGroupsWithState</p>
      - <p>flatMapGroupsWithState</p>

    <p>**This course is for Scala and Spark programmers who need to process streaming data rather than one-time or batch. If you've never done Scala or Spark, this course is not for you.**</p>

    ### Project 1: Twitter

    In this project we will integrate live data from Twitter. We will create a custom data source that we use with Spark, and we will do various analyses: tweet lengths, most used hashtags in real time. You will be able to use this project as a blueprint for any data source that you might want to integrate. At the very end, we will use an NLP library from Stanford to do sentiment analysis on tweets and find the general state of social media.

    You will learn:

      - <p>How to set up your own data receiver, that you can manage yourself and "pull" new data</p>
      - <p>How to create a DStream from your custom code</p>
      - <p>How to pull data from Twitter</p>
      - <p>How to aggregate tweets</p>
      - <p>How to use Stanford's coreNLP library for sentiment analysis</p>
      - <p>How to apply sentiment analysis on tweets in real time</p>

    ### Project 2: A Science Project

    In this project we will write a full-stack web application which will support multiple users that are test subjects of a scientific test. We will investigate the effects of alcohol/substances/insert_your_addictive_drug_like_Scala on reflexes and response times. We will send the data through a web UI connected to a REST endpoint, then the data will flow through a Kafka broker and finally to a Spark Streaming backend which will do the data crunching. You can use this application as a blueprint for any full-stack application that aggregates and processes data with Spark Streaming in real time, from any number of concurrent users.

    You will learn:

    - <p>How to set up an HTTP server in minutes with Akka HTTP</p>
    - <p>How to manually send data through Kafka</p>
    - <p>How to aggregate data in a way that's almost impossible in SQL</p>
    - <p>How to write a full-stack application with a web UI, Akka HTTP, Kafka and Spark Streaming</p>

  </Fragment>
</CourseLayout>
